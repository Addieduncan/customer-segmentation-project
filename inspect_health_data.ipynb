{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f65f367",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get the packages we need to manipulate the dataset \n",
    "\"\"\"\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94c93ca3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DATA_PATH is not valid path",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t_/fh2xbl3j5q39d2w_3ssqg1_c0000gn/T/ipykernel_40776/775253295.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DATA_PATH is good path'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DATA_PATH is not valid path'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: DATA_PATH is not valid path"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Specify the directories for data. These are universal for our repository-\n",
    "this is the only thing you should not change.\n",
    "\"\"\"\n",
    "\n",
    "#rewrite this in the preferred way using os.join and os.path \n",
    "\n",
    "DATA_DIR = './' + 'raw_data'\n",
    "\n",
    "DATA_NAME = '/diabetic_data.csv'\n",
    "\n",
    "DATA_PATH = DATA_DIR + DATA_NAME\n",
    "\n",
    "os.listdir(DATA_DIR)\n",
    "\n",
    "if os.path.isfile(DATA_PATH): \n",
    "    print('DATA_PATH is good path')\n",
    "else:\n",
    "    raise ValueError('DATA_PATH is not valid path')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define size of data sample to read-in. Use to_skip to define the logic. \n",
    "\n",
    "Import data as pandas dataframe for that format \n",
    "\"\"\"\n",
    "\n",
    "SAMPLE_SIZE = (10**4)\n",
    "\n",
    "def to_skip(index): \n",
    "    \"\"\"\n",
    "    Function to be used with pandas skiprows\n",
    "    \"\"\"\n",
    "    keeprow = False\n",
    "    \n",
    "    if index <= SAMPLE_SIZE:\n",
    "        keeprow = True\n",
    "    else:\n",
    "        keeprow = False\n",
    "    \n",
    "    return keeprow\n",
    "\n",
    "raw_data = pd.read_csv(DATA_PATH,nrows = SAMPLE_SIZE)\n",
    "                                              \n",
    "print(raw_data.shape)\n",
    "raw_data.head(10)\n",
    "print(raw_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9f9b87",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Process raw data according to the values which are missing. Define the features to keep based on initial report of \n",
    "completeness and information\n",
    "\"\"\"\n",
    "raw_data.columns\n",
    "\n",
    "\n",
    "to_keep = ['race','gender','age','weight','admission_type_id','discharge_disposition_id',\\\n",
    "           'time_in_hospital','num_lab_procedures','num_procedures','num_medications',\n",
    "           'number_outpatient','number_emergency','number_inpatient','diag_1','diag_2']\n",
    "           \n",
    "           \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01328dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8788e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define the features desired to keep based on the initial summary of data completeness provided here: \n",
    "\n",
    "https://www.hindawi.com/journals/bmri/2014/781670/tab1/\n",
    "\n",
    "This cell is intended only for list manipulation - we actually slice the data in the next cell \n",
    "\"\"\" \n",
    "\n",
    "features = raw_data.columns\n",
    "print('Here are all possible features: \\n\\n',features,'\\n')\n",
    "\n",
    "#Here are the 'simple' features identified by Will - we roughly know how to interpret these \n",
    "ft_basic = ['race','gender','age','admission_type_id','discharge_disposition_id',\n",
    "          'time_in_hospital','num_lab_procedures','num_procedures','num_medications', 'number_outpatient',\\\n",
    "           'number_emergency','number_inpatient','number_diagnoses','change',\\\n",
    "            'diabetesMed', 'readmitted']\n",
    "\n",
    "ft_basic_keep = ft_basic[:]\n",
    "\n",
    "#Here are complex medical features we do not understand \n",
    "\n",
    "ft_med = ['diag_1','diag_2','diag_3','max_glu_serum', 'A1Cresult',\n",
    "       'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
    "       'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
    "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
    "       'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
    "       'glyburide-metformin', 'glipizide-metformin',\n",
    "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
    "       'metformin-pioglitazone']\n",
    "\n",
    "ft_med_keep = list()\n",
    "\n",
    "#Here are all the features we will keep or toss \n",
    "ft_keep = ft_basic_keep + ft_med_keep \n",
    "ft_toss = [x for x in features if (x in features) and (x not in ft_keep)]\n",
    "\n",
    "print('Here are the features we decided to keep:\\n\\n', ft_keep,'\\n')\n",
    "print('Here are the features we decided to eliminate: \\n\\n',ft_toss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70560f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Subset the Raw Data: Here, we refine data according to the desired features to keep defined in the preivous cell. Then \n",
    "we type convert the columns in order to actually apply clustering to them. \n",
    "\"\"\"\n",
    "data = raw_data[ft_keep]\n",
    "ft_kept = data.columns \n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c44af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Clean the Data: Here we identify rows with missing fields in the desired categories. First, nan/None type is filtered and \n",
    "the row number is added to a list of rows which will be skipped when reading in the data for processing\n",
    "\"\"\"\n",
    "\n",
    "#Iterate over the list of desired features to keep; extract the series aech time, and build the list of rows associated\n",
    "#to a missing data value available in that series. This is better than simply calling .dropna() one time \n",
    "\n",
    "rows_nan = list()\n",
    "\n",
    "#This is an iterative approach by checking each column - this can likely be done across the whole array simultaneously \n",
    "\n",
    "for feature in ft_kept:\n",
    "    feature_series = data[feature]\n",
    "    missing_bool = feature_series.isnull()\n",
    "    nan_indices = feature_series.index[missing_bool]\n",
    "    print(nan_indices)\n",
    "    \n",
    "value_dictionary = dict()\n",
    "for feature in ft_kept:\n",
    "    feature_series = data[feature]\n",
    "    unique_vals = list()\n",
    "    for x in feature_series:\n",
    "        if x in unique_vals:\n",
    "            pass\n",
    "        else: \n",
    "            unique_vals.append(x)\n",
    "    value_dictionary[feature] = unique_vals\n",
    "\n",
    "#Here are the available values in each feature that are stored \n",
    "print(value_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce3e0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72cd983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
